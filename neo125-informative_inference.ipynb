{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68efd6da-1eb7-4c50-bd54-2739625d198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from GPTNeoWithIntermediates import GPTNeoWithIntermediates\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc38a80-2036-441f-ab92-69e8f560b648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoWithIntermediates(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "model = GPTNeoWithIntermediates.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afd3774-17f4-4a1a-ba94-08bc064fbc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd77bdd4-02d1-4edd-bf86-6d9d5455f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the padding token to the eos_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def perform_inference_with_all_intermediates(input_texts, selected_layers=None):\n",
    "    # Tokenize the input texts in parallel\n",
    "    inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    print(inputs)\n",
    "    input_ids, attention_mask = inputs.input_ids, inputs.attention_mask\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    predicted_ids = torch.argmax(outputs[\"logits\"], dim=-1)\n",
    "    generated_texts = [tokenizer.decode(ids, skip_special_tokens=True) for ids in predicted_ids]\n",
    "\n",
    "    if selected_layers is None:\n",
    "        selected_layers = list(range(len(outputs[\"layer_outputs\"])))\n",
    "    \n",
    "    # Extract the intermediate outputs for selected layers for each input\n",
    "    selected_outputs = [\n",
    "        {i: layer_output for i, layer_output in enumerate(outputs[\"layer_outputs\"]) if i in selected_layers}\n",
    "        for _ in input_texts\n",
    "    ]\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"generated_text\": generated_texts[idx],\n",
    "            \"layer_outputs\": selected_outputs[idx],\n",
    "        }\n",
    "        for idx in range(len(input_texts))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "073a6f17-0de0-40f3-864c-651b1827d76b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 7454,  2402,   257,   640, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [  464,  2068,  7586, 21831, 18045,   625,   262, 16931,  3290, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [   65,  5758, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [  950,   278,   286,   262,  1613,  9303,  1810,   547,   262,   262,\n",
      "           726,   338,  8350,   881,   287,   262,  1605,   286, 10815,   286,\n",
      "           262,  1605, 34507,   286,   547,   492,   262,    11,   262,   373,\n",
      "           262, 11483,   286,  1862,  5352,   703,  6817,  2126,   286,   606,\n",
      "           278,   257,   257,  1266,   835,   284,  1592,   257,  7937, 29853,\n",
      "          5643,    13]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]], device='cuda:0')}\n",
      "1.2040786743164062\n",
      "Generated Text for input 1:  I a time, the the the the the the the the the the the the the the the the the the the,,,,, the the the the the the I the I I the the the the the the the the I,\n",
      " the the I\n",
      "Generated Text for input 2:  present- eyeses out the fence dog and- tail tail tail tail tail tail tail tail, the the the\n",
      "\n",
      "\n",
      "ll Ai Ai Ai Ai and Ai Ai and and and and Fox Fox- Fox- Fox Fox Fox and Fox Fox-- and\n",
      "Generated Text for input 3: ), the*----///////////////////////\n",
      "// the the the the//-/-///-//-/,\n",
      "Generated Text for input 4: ing the the world,\n",
      "\n",
      " the mostsesahs\n",
      " for more the past Revolution the. the Revolution Revolution\n",
      " the the\n",
      " American the, the, of the menists to of of the was of,, of to the the war.. of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"Once upon a time\", \"The quick brown fox jumps over the lazy dog\", \"brave\", \"ollowing of the past Revolution War were the theoy's fought much in the American of tactics of the American-. of were.. the, the was the lesson of young strateg how importance idea of theming a a best way to win a shipscladads.\"]\n",
    "selected_layers = [1, 5, 11]\n",
    "\n",
    "t = time.time()\n",
    "results = perform_inference_with_all_intermediates(input_texts, selected_layers)\n",
    "print(time.time() - t)\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    print(f\"Generated Text for input {idx + 1}: {result['generated_text']}\")\n",
    "    # for layer_num, layer_output in result[\"layer_outputs\"].items():\n",
    "    #     print(f\"Layer {layer_num} - Attention Block Output Shape:\", layer_output[\"attn_out\"].shape)\n",
    "    #     print(f\"Layer {layer_num} - MLP Hidden Output Shape:\", layer_output[\"mlp_hidden\"].shape)\n",
    "    #     print(f\"Layer {layer_num} - MLP Final Output Shape:\", layer_output[\"mlp_final\"].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
